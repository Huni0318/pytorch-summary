{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aHYslj8J-ZdS"
   },
   "source": [
    "# 4. 인공 신경망\n",
    "\n",
    "인공 신경망은 사람의 신경망을 모사하여 만든 예측 도구이다. 기본적으로 하나의 레이어에 다수의 노드를 가지고 있으며 여러 개의 레이어가 쌓인 신경망을\n",
    "깊은 신경망이라고 한다. 이 때, 깊은 신경망을 이용하여 모델을 학습 시키는 방법을 딥러닝이라고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn.datasets에서는 다양한 데이터들을 제공한다.\n",
    "# https://scikit-learn.org/stable/datasets/index.html\n",
    "\n",
    "from sklearn.datasets import load_boston # 보스턴 집 값 데이터를 불러온다.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split # 전체 데이터를 학습 데이터와 평가 데이터로 나눈다.\n",
    "from sklearn.preprocessing import MinMaxScaler # 데이터 내의 값을 0이상 1이하의 값으로 조정\n",
    "\n",
    "# ANN\n",
    "import torch\n",
    "from torch import nn, optim # torch 내의 세부적인 기능을 불러온다. (신경망 기술, 손실함수, 최적화 방법 등)\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset # 데이터를 모델에 사용할 수 있도록 정리해 주는 라이브러리\n",
    "import torch.nn.functional as F # torch 내의 세부적인 기능을 불러온다. (신경망 기술 등)\n",
    "\n",
    "# Loss\n",
    "from sklearn.metrics import mean_squared_error # Regression 문제의 평가를 위해 MSE(Mean Squared Error)를 불러온다.\n",
    "\n",
    "# Plot\n",
    "import matplotlib.pyplot as plt # 시각화 도구"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x5_AHWh3-Zdd"
   },
   "source": [
    "## 4.1 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bos = load_boston() # 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.02985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.430</td>\n",
       "      <td>58.7</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.12</td>\n",
       "      <td>5.21</td>\n",
       "      <td>28.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.08829</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.012</td>\n",
       "      <td>66.6</td>\n",
       "      <td>5.5605</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>395.60</td>\n",
       "      <td>12.43</td>\n",
       "      <td>22.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.14455</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.172</td>\n",
       "      <td>96.1</td>\n",
       "      <td>5.9505</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>19.15</td>\n",
       "      <td>27.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.21124</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>5.631</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.0821</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.63</td>\n",
       "      <td>29.93</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.17004</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.004</td>\n",
       "      <td>85.9</td>\n",
       "      <td>6.5921</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.71</td>\n",
       "      <td>17.10</td>\n",
       "      <td>18.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM    AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575   65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421   78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185   61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998   45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147   54.2  6.0622  3.0  222.0   \n",
       "5  0.02985   0.0   2.18   0.0  0.458  6.430   58.7  6.0622  3.0  222.0   \n",
       "6  0.08829  12.5   7.87   0.0  0.524  6.012   66.6  5.5605  5.0  311.0   \n",
       "7  0.14455  12.5   7.87   0.0  0.524  6.172   96.1  5.9505  5.0  311.0   \n",
       "8  0.21124  12.5   7.87   0.0  0.524  5.631  100.0  6.0821  5.0  311.0   \n",
       "9  0.17004  12.5   7.87   0.0  0.524  6.004   85.9  6.5921  5.0  311.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  Price  \n",
       "0     15.3  396.90   4.98   24.0  \n",
       "1     17.8  396.90   9.14   21.6  \n",
       "2     17.8  392.83   4.03   34.7  \n",
       "3     18.7  394.63   2.94   33.4  \n",
       "4     18.7  396.90   5.33   36.2  \n",
       "5     18.7  394.12   5.21   28.7  \n",
       "6     15.2  395.60  12.43   22.9  \n",
       "7     15.2  396.90  19.15   27.1  \n",
       "8     15.2  386.63  29.93   16.5  \n",
       "9     15.2  386.71  17.10   18.9  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bos 내에는 data, feature name 등 다양한 정보를 포함하고 있다.\n",
    "df = pd.DataFrame(bos.data) # 데이터의 변수를 데이터프레임으로 만들기 \n",
    "df.columns = bos.feature_names # 데이터 변수명 불러오기\n",
    "df['Price'] = bos.target # 집 값에 해당하는 타겟 값 불러오기\n",
    "\n",
    "# 데이터프레임 보여주기\n",
    "# df.head()는 상위 5줄만 보여준다.\n",
    "# df.head(10) 괄호 안에 숫자 10을 넣으면 10줄을 보여준다. \n",
    "df.head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description in Korean\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "** 데이터 변수 설명 **\n",
    "\n",
    "CRIM: 범죄율\n",
    "INDUS: 비소매상업지역 면적 비율\n",
    "NOX: 일산화질소 농도\n",
    "RM: 주택당 방 수\n",
    "LSTAT: 인구 중 하위 계층 비율\n",
    "B: 인구 중 흑인 비율\n",
    "PTRATIO: 학생/교사 비율\n",
    "ZN: 25,000 평방피트를 초과 거주지역 비율\n",
    "CHAS: 찰스강의 경계에 위치한 경우는 1, 아니면 0\n",
    "AGE: 1940년 이전에 건축된 주택의 비율\n",
    "RAD: 방사형 고속도로까지의 거리\n",
    "DIS: 직업센터의 거리\n",
    "TAX: 재산세율\n",
    "\"\"\"\n",
    "print(\"Description in Korean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LJiezl97-Zdg"
   },
   "source": [
    "## 4.2 목표 성능 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.08019\n"
     ]
    }
   ],
   "source": [
    "# 우리가 만든 인공 신경망의 성능이 어느 정도인지 판단하기 위해 베이스라인을 정해보자.\n",
    "# Multithreaded Local Learning Regularization Neural Networks for Regression Tasks, 2015\n",
    "# 위 논문에서 보스턴 집 값 예측의 성능은 RMSE=0.08019이다.\n",
    "# 따라서 실험 조건을 동일하게 하고 RMSE를 측정하여 아래 정의 된 인공 신경망의 성능을 확인하자.\n",
    "print(\"RMSE: 0.08019\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H7xSCb7b-Zdh"
   },
   "source": [
    "## 4.3 데이터 스케일링(MinMax Scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 넘파이 배열로 만들기\n",
    "X = df.drop('Price', axis=1).to_numpy() # 데이터프레임에서 타겟값(Price)을 제외하고 넘파이 배열로 만들기\n",
    "Y = df['Price'].to_numpy().reshape((-1,1)) # 데이터프레임 형태의 타겟값을 넘파이 배열로 만들기\n",
    "\n",
    "# 데이터 스케일링\n",
    "# sklearn에서 제공하는 MinMaxScaler \n",
    "# (X-min(X))/(max(X)-min(X))을 계산\n",
    "scaler = MinMaxScaler() \n",
    "scaler.fit(X) \n",
    "X = scaler.transform(X)\n",
    "\n",
    "scaler.fit(Y)\n",
    "Y = scaler.transform(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Luh06zYz-Zdi"
   },
   "source": [
    "## 4.4 텐서 데이터와 배치 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서 데이터로 변환하는 클래스(3강 참고)\n",
    "class TensorData(Dataset):\n",
    "\n",
    "    def __init__(self, x_data, y_data):\n",
    "        self.x_data = torch.FloatTensor(x_data)\n",
    "        self.y_data = torch.FloatTensor(y_data)\n",
    "        self.len = self.y_data.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        return self.x_data[index], self.y_data[index] \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 데이터를 학습 데이터와 평가 데이터로 나눈다.\n",
    "# 기준으로 잡은 논문이 전체 데이터를 50%, 50%로 나눴기 때문에 test size를 0.5로 설정한다.\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.5)\n",
    "\n",
    "# 학습 데이터, 시험 데이터 배치 형태로 구축하기\n",
    "trainsets = TensorData(X_train, Y_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainsets, batch_size=32, shuffle=True)\n",
    "\n",
    "testsets = TensorData(X_test, Y_test)\n",
    "testloader = torch.utils.data.DataLoader(testsets, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UQh9Ds34-Zdj"
   },
   "source": [
    "## 4.5 모델 구축\n",
    "\n",
    "모델은 Regressor로 정의하며 입력층(노드 13개), 2개의 은닉층(50, 30개), 출력층(1개)으로 구성한다. 데이터의 변수는 13개이므로 입력층의 노드는\n",
    "13개가 되고 출력층은 집 값인 단일 값을 추출하는 것이므로 1개가 된다. 은닉층에 대해서는 실험을 하면서 튜닝할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() # 모델 연산 정의\n",
    "        self.fc1 = nn.Linear(13, 50, bias=True) # 입력층(13) -> 은닉층1(50)으로 가는 연산\n",
    "        self.fc2 = nn.Linear(50, 30, bias=True) # 은닉층1(50) -> 은닉층2(30)으로 가는 연산\n",
    "        self.fc3 = nn.Linear(30, 1, bias=True) # 은닉층2(30) -> 출력층(1)으로 가는 연산\n",
    "        self.dropout = nn.Dropout(0.2) # 연산이 될 때마다 20%의 비율로 랜덤하게 노드를 없앤다.\n",
    "\n",
    "    def forward(self, x): # 모델 연산의 순서를 정의\n",
    "        x = F.relu(self.fc1(x)) # Linear 계산 후 활성화 함수 ReLU를 적용한다.  \n",
    "        x = self.dropout(F.relu(self.fc2(x))) # 은닉층2에서 드랍아웃을 적용한다.(즉, 30개의 20%인 6개의 노드가 계산에서 제외된다.)\n",
    "        x = F.relu(self.fc3(x)) # Linear 계산 후 활성화 함수 ReLU를 적용한다.  \n",
    "      \n",
    "        return x\n",
    "    \n",
    "# 주의 사항\n",
    "# 드랍아웃은 과적합(overfitting)을 방지하기 위해 노드의 일부를 배제하고 계산하는 방식이기 때문에 절대로 출력층에 사용해서는 안 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l6v6VEOb-Zdk"
   },
   "source": [
    "## 4.6 모델, 손실함수, 최적화 방법 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Regressor()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# lr은 학습률이다.\n",
    "# weight_decay는 L2 정규화에서의 penalty 정도를 의미한다.\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67u82MtW-Zdl"
   },
   "source": [
    "## 4.7 학습 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "loss_ = [] # 그래프를 그리기 위한 loss 저장용 리스트 \n",
    "n = len(trainloader)\n",
    "\n",
    "for epoch in range(400): # 400번 학습을 진행한다.\n",
    "\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(trainloader, 0): # 무작위로 섞인 32개 데이터가 있는 배치가 하나 씩 들어온다.\n",
    "\n",
    "        inputs, values = data # data에는 X, Y가 들어있다.\n",
    "\n",
    "        optimizer.zero_grad() # 최적화 초기화\n",
    "        \n",
    "        outputs = model(inputs) # 모델에 입력값 대입 후 예측값 산출\n",
    "        loss = criterion(outputs, values) # 손실 함수 계산\n",
    "        loss.backward() # 손실 함수 기준으로 역전파 설정 \n",
    "        optimizer.step() # 역전파를 진행하고 가중치 업데이트\n",
    "        \n",
    "        running_loss += loss.item() # epoch 마다 평균 loss를 계산하기 위해 배치 loss를 더한다.\n",
    " \n",
    "\n",
    "    loss_.append(running_loss/n) # MSE(Mean Squared Error) 계산\n",
    "\n",
    "        \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_)\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fVxTzgL8-Zdn"
   },
   "source": [
    "## 4.8 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(dataloader):\n",
    "    \n",
    "    predictions = torch.tensor([], dtype=torch.float) # 예측값을 저장하는 텐서\n",
    "    actual = torch.tensor([], dtype=torch.float) # 실제값을 저장하는 텐서\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        model.eval() # 평가를 할 때에는 .eval() 반드시 사용해야 한다.\n",
    "        for data in dataloader:\n",
    "            inputs, values = data\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            predictions = torch.cat((predictions, outputs), 0) # cat을 통해 예측값을 누적\n",
    "            actual = torch.cat((actual, values), 0) # cat을 통해 실제값을 누적\n",
    "    \n",
    "    predictions = predictions.numpy() # 넘파이 배열로 변경\n",
    "    actual = actual.numpy() # 넘파이 배열로 변경\n",
    "    rmse = np.sqrt(mean_squared_error(predictions, actual)) # sklearn을 이용하여 RMSE 계산\n",
    "    \n",
    "    return rmse  \n",
    "\n",
    "# 평가 시 .eval()을 사용해야 하는 이유\n",
    "# 평가 시에는 온전한 모델로 평가를 해야하는데 .eval()이 아닌 .train()인 경우 드랍아웃이 활성화 되어 있다.\n",
    "# 따라서 드랍아웃이나 배치 정규화 등과 같이 학습 시에만 사용하는 기술들을 평가 시에는 비활성화 해야만 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  0.039059013\n",
      "Test RMSE:  0.07430778\n"
     ]
    }
   ],
   "source": [
    "train_rmse = evaluation(trainloader) # 학습 데이터의 RMSE\n",
    "test_rmse = evaluation(testloader) # 시험 데이터의 RMSE\n",
    "\n",
    "print(\"Train RMSE: \",train_rmse)\n",
    "print(\"Test RMSE: \",test_rmse)\n",
    "\n",
    "# 예시를 위한 단순 비교입니다. 실제 연구에서는 디테일한 비교가 필요합니다.\n",
    "# 비교 논문에서는 20번의 평가 결과의 평균으로 결과값을 산정 했습니다.\n",
    "# 데이터를 무작위로 나누고 모델의 초기값도 random initial parameter를 사용했기 때문에 학습을 할 때 마다 결과가 다르게 나올 수 있습니다.\n",
    "# 이 강의에서는 학습의 흐름(for문)과 모델(Regressor) 부분을 주의 깊게 보시면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.08019\n"
     ]
    }
   ],
   "source": [
    "# Multithreaded Local Learning Regularization Neural Networks for Regression Tasks, 2015\n",
    "print(\"RMSE: 0.08019\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
